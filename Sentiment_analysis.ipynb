{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"toc_visible":true,"authorship_tag":"ABX9TyM/2i0Iugt0nbk5fnZP51wj"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["import nltk\n","nltk.download('stopwords')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vZmWwf62GMB-","executionInfo":{"status":"ok","timestamp":1698476654638,"user_tz":-330,"elapsed":1327,"user":{"displayName":"Garima Singh","userId":"07177206605986055763"}},"outputId":"53f81d23-0746-40c4-9370-ae674e892966"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":8}]},{"cell_type":"code","execution_count":9,"metadata":{"id":"Ecq9YZ_u-W4j","executionInfo":{"status":"ok","timestamp":1698476659945,"user_tz":-330,"elapsed":4,"user":{"displayName":"Garima Singh","userId":"07177206605986055763"}}},"outputs":[],"source":["import pandas as pd    # to load dataset\n","import numpy as np     # for mathematic equation\n","from nltk.corpus import stopwords   # to get collection of stopwords\n","from sklearn.model_selection import train_test_split       # for splitting dataset\n","from tensorflow.keras.preprocessing.text import Tokenizer  # to encode text to int\n","from tensorflow.keras.preprocessing.sequence import pad_sequences   # to do padding or truncating\n","from tensorflow.keras.models import Sequential     # the model\n","from tensorflow.keras.layers import Embedding, LSTM, Dense # layers of the architecture\n","from tensorflow.keras.callbacks import ModelCheckpoint   # save model\n","from tensorflow.keras.models import load_model   # load saved model\n","import re"]},{"cell_type":"markdown","source":["Preview dataset\n"],"metadata":{"id":"H_yO8sRv-q77"}},{"cell_type":"code","source":["from google.colab import files\n","\n","\n","uploaded = files.upload()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":73},"id":"JAbIltKY-gyB","executionInfo":{"status":"ok","timestamp":1698475789332,"user_tz":-330,"elapsed":1090060,"user":{"displayName":"Garima Singh","userId":"07177206605986055763"}},"outputId":"050305d1-1aaa-4cf0-8f2d-ab12703efc90"},"execution_count":2,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","     <input type=\"file\" id=\"files-6b12e47c-5d54-4b04-87b9-7f9f4421a09b\" name=\"files[]\" multiple disabled\n","        style=\"border:none\" />\n","     <output id=\"result-6b12e47c-5d54-4b04-87b9-7f9f4421a09b\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script>// Copyright 2017 Google LLC\n","//\n","// Licensed under the Apache License, Version 2.0 (the \"License\");\n","// you may not use this file except in compliance with the License.\n","// You may obtain a copy of the License at\n","//\n","//      http://www.apache.org/licenses/LICENSE-2.0\n","//\n","// Unless required by applicable law or agreed to in writing, software\n","// distributed under the License is distributed on an \"AS IS\" BASIS,\n","// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","// See the License for the specific language governing permissions and\n","// limitations under the License.\n","\n","/**\n"," * @fileoverview Helpers for google.colab Python module.\n"," */\n","(function(scope) {\n","function span(text, styleAttributes = {}) {\n","  const element = document.createElement('span');\n","  element.textContent = text;\n","  for (const key of Object.keys(styleAttributes)) {\n","    element.style[key] = styleAttributes[key];\n","  }\n","  return element;\n","}\n","\n","// Max number of bytes which will be uploaded at a time.\n","const MAX_PAYLOAD_SIZE = 100 * 1024;\n","\n","function _uploadFiles(inputId, outputId) {\n","  const steps = uploadFilesStep(inputId, outputId);\n","  const outputElement = document.getElementById(outputId);\n","  // Cache steps on the outputElement to make it available for the next call\n","  // to uploadFilesContinue from Python.\n","  outputElement.steps = steps;\n","\n","  return _uploadFilesContinue(outputId);\n","}\n","\n","// This is roughly an async generator (not supported in the browser yet),\n","// where there are multiple asynchronous steps and the Python side is going\n","// to poll for completion of each step.\n","// This uses a Promise to block the python side on completion of each step,\n","// then passes the result of the previous step as the input to the next step.\n","function _uploadFilesContinue(outputId) {\n","  const outputElement = document.getElementById(outputId);\n","  const steps = outputElement.steps;\n","\n","  const next = steps.next(outputElement.lastPromiseValue);\n","  return Promise.resolve(next.value.promise).then((value) => {\n","    // Cache the last promise value to make it available to the next\n","    // step of the generator.\n","    outputElement.lastPromiseValue = value;\n","    return next.value.response;\n","  });\n","}\n","\n","/**\n"," * Generator function which is called between each async step of the upload\n"," * process.\n"," * @param {string} inputId Element ID of the input file picker element.\n"," * @param {string} outputId Element ID of the output display.\n"," * @return {!Iterable<!Object>} Iterable of next steps.\n"," */\n","function* uploadFilesStep(inputId, outputId) {\n","  const inputElement = document.getElementById(inputId);\n","  inputElement.disabled = false;\n","\n","  const outputElement = document.getElementById(outputId);\n","  outputElement.innerHTML = '';\n","\n","  const pickedPromise = new Promise((resolve) => {\n","    inputElement.addEventListener('change', (e) => {\n","      resolve(e.target.files);\n","    });\n","  });\n","\n","  const cancel = document.createElement('button');\n","  inputElement.parentElement.appendChild(cancel);\n","  cancel.textContent = 'Cancel upload';\n","  const cancelPromise = new Promise((resolve) => {\n","    cancel.onclick = () => {\n","      resolve(null);\n","    };\n","  });\n","\n","  // Wait for the user to pick the files.\n","  const files = yield {\n","    promise: Promise.race([pickedPromise, cancelPromise]),\n","    response: {\n","      action: 'starting',\n","    }\n","  };\n","\n","  cancel.remove();\n","\n","  // Disable the input element since further picks are not allowed.\n","  inputElement.disabled = true;\n","\n","  if (!files) {\n","    return {\n","      response: {\n","        action: 'complete',\n","      }\n","    };\n","  }\n","\n","  for (const file of files) {\n","    const li = document.createElement('li');\n","    li.append(span(file.name, {fontWeight: 'bold'}));\n","    li.append(span(\n","        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n","        `last modified: ${\n","            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n","                                    'n/a'} - `));\n","    const percent = span('0% done');\n","    li.appendChild(percent);\n","\n","    outputElement.appendChild(li);\n","\n","    const fileDataPromise = new Promise((resolve) => {\n","      const reader = new FileReader();\n","      reader.onload = (e) => {\n","        resolve(e.target.result);\n","      };\n","      reader.readAsArrayBuffer(file);\n","    });\n","    // Wait for the data to be ready.\n","    let fileData = yield {\n","      promise: fileDataPromise,\n","      response: {\n","        action: 'continue',\n","      }\n","    };\n","\n","    // Use a chunked sending to avoid message size limits. See b/62115660.\n","    let position = 0;\n","    do {\n","      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n","      const chunk = new Uint8Array(fileData, position, length);\n","      position += length;\n","\n","      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n","      yield {\n","        response: {\n","          action: 'append',\n","          file: file.name,\n","          data: base64,\n","        },\n","      };\n","\n","      let percentDone = fileData.byteLength === 0 ?\n","          100 :\n","          Math.round((position / fileData.byteLength) * 100);\n","      percent.textContent = `${percentDone}% done`;\n","\n","    } while (position < fileData.byteLength);\n","  }\n","\n","  // All done.\n","  yield {\n","    response: {\n","      action: 'complete',\n","    }\n","  };\n","}\n","\n","scope.google = scope.google || {};\n","scope.google.colab = scope.google.colab || {};\n","scope.google.colab._files = {\n","  _uploadFiles,\n","  _uploadFilesContinue,\n","};\n","})(self);\n","</script> "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Saving imdb_reviews.csv to imdb_reviews.csv\n"]}]},{"cell_type":"code","source":["data = pd.read_csv('imdb_reviews.csv')\n","\n","print(data)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CkZaWgNIFHug","executionInfo":{"status":"ok","timestamp":1698476394944,"user_tz":-330,"elapsed":1231,"user":{"displayName":"Garima Singh","userId":"07177206605986055763"}},"outputId":"10b15366-4fcb-4da1-c26c-f36000b358f7"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["                                                  review sentiment\n","0      One of the other reviewers has mentioned that ...  positive\n","1      A wonderful little production. <br /><br />The...  positive\n","2      I thought this was a wonderful way to spend ti...  positive\n","3      Basically there's a family where a little boy ...  negative\n","4      Petter Mattei's \"Love in the Time of Money\" is...  positive\n","...                                                  ...       ...\n","49995  I thought this movie did a down right good job...  positive\n","49996  Bad plot, bad dialogue, bad acting, idiotic di...  negative\n","49997  I am a Catholic taught in parochial elementary...  negative\n","49998  I'm going to have to disagree with the previou...  negative\n","49999  No one expects the Star Trek movies to be high...  negative\n","\n","[50000 rows x 2 columns]\n"]}]},{"cell_type":"code","source":["english_stops = set(stopwords.words('english'))"],"metadata":{"id":"jsPjuYOQGDY7","executionInfo":{"status":"ok","timestamp":1698476665186,"user_tz":-330,"elapsed":4,"user":{"displayName":"Garima Singh","userId":"07177206605986055763"}}},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":["**Load and Clean Dataset**\n","\n","In the original dataset, the reviews are still dirty. There are still html tags, numbers, uppercase, and punctuations. This will not be good for training, so in load_dataset() function, beside loading the dataset using pandas, I also pre-process the reviews by removing html tags, non alphabet (punctuations and numbers), stop words, and lower case all of the reviews."],"metadata":{"id":"15Za9DPKFeth"}},{"cell_type":"code","source":["def load_dataset():\n","    df = pd.read_csv('imdb_reviews.csv')\n","    x_data = df['review']       # Reviews/Input\n","    y_data = df['sentiment']    # Sentiment/Output\n","\n","    # PRE-PROCESS REVIEW\n","    x_data = x_data.replace({'<.*?>': ''}, regex = True)          # remove html tag\n","    x_data = x_data.replace({'[^A-Za-z]': ' '}, regex = True)     # remove non alphabet\n","    x_data = x_data.apply(lambda review: [w for w in review.split() if w not in english_stops])  # remove stop words\n","    x_data = x_data.apply(lambda review: [w.lower() for w in review])   # lower case\n","\n","    # ENCODE SENTIMENT -> 0 & 1\n","    y_data = y_data.replace('positive', 1)\n","    y_data = y_data.replace('negative', 0)\n","\n","    return x_data, y_data\n","\n","x_data, y_data = load_dataset()\n","\n","print('Reviews')\n","print(x_data, '\\n')\n","print('Sentiment')\n","print(y_data)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_KIxctawFfgx","executionInfo":{"status":"ok","timestamp":1698476681366,"user_tz":-330,"elapsed":10645,"user":{"displayName":"Garima Singh","userId":"07177206605986055763"}},"outputId":"98ac307a-2522-4b03-f74b-45f847123dfb"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["Reviews\n","0        [one, reviewers, mentioned, watching, oz, epis...\n","1        [a, wonderful, little, production, the, filmin...\n","2        [i, thought, wonderful, way, spend, time, hot,...\n","3        [basically, family, little, boy, jake, thinks,...\n","4        [petter, mattei, love, time, money, visually, ...\n","                               ...                        \n","49995    [i, thought, movie, right, good, job, it, crea...\n","49996    [bad, plot, bad, dialogue, bad, acting, idioti...\n","49997    [i, catholic, taught, parochial, elementary, s...\n","49998    [i, going, disagree, previous, comment, side, ...\n","49999    [no, one, expects, star, trek, movies, high, a...\n","Name: review, Length: 50000, dtype: object \n","\n","Sentiment\n","0        1\n","1        1\n","2        1\n","3        0\n","4        1\n","        ..\n","49995    1\n","49996    0\n","49997    0\n","49998    0\n","49999    0\n","Name: sentiment, Length: 50000, dtype: int64\n"]}]},{"cell_type":"markdown","source":["Split Dataset"],"metadata":{"id":"qu2FyoT5GbY6"}},{"cell_type":"code","source":["x_train, x_test, y_train, y_test = train_test_split(x_data, y_data, test_size = 0.2)\n","\n","print('Train Set')\n","print(x_train, '\\n')\n","print(x_test, '\\n')\n","print('Test Set')\n","print(y_train, '\\n')\n","print(y_test)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Bwo-TEoHGcXI","executionInfo":{"status":"ok","timestamp":1698476718127,"user_tz":-330,"elapsed":559,"user":{"displayName":"Garima Singh","userId":"07177206605986055763"}},"outputId":"0642ea48-d7be-45a9-ee6e-afd8e7e62205"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["Train Set\n","48052    [i, love, don, knotts, let, say, front, he, en...\n","22663    [in, film, blow, up, antonioni, hero, question...\n","45296    [woof, pretty, boring, might, well, shot, blac...\n","13735    [i, checked, movie, based, favorable, review, ...\n","321      [i, watched, movie, countless, times, never, f...\n","                               ...                        \n","11441    [mild, spoilers, with, exception, the, termina...\n","38754    [you, lived, japan, awhile, enjoy, beauty, mov...\n","17944    [i, found, charming, adaptation, lively, full,...\n","29520    [as, spiritualist, non, christian, i, thought,...\n","627      [why, canada, turn, decent, good, movies, ever...\n","Name: review, Length: 40000, dtype: object \n","\n","49309    [did, writers, pay, people, come, write, posit...\n","39185    [wolfgang, peterson, directs, thriller, clint,...\n","872      [this, second, hitchcock, film, appear, list, ...\n","7783     [because, writers, guild, america, strike, sho...\n","20441    [a, great, storyline, message, joan, plowright...\n","                               ...                        \n","14945    [this, second, british, rank, film, adapt, sto...\n","42896    [every, film, comes, along, characters, know, ...\n","17572    [the, dead, truly, work, art, clearly, john, h...\n","20051    [first, dilettantish, try, describe, way, hist...\n","22697    [the, write, wordwhat, see, get, not, really, ...\n","Name: review, Length: 10000, dtype: object \n","\n","Test Set\n","48052    0\n","22663    0\n","45296    0\n","13735    0\n","321      1\n","        ..\n","11441    0\n","38754    1\n","17944    1\n","29520    0\n","627      0\n","Name: sentiment, Length: 40000, dtype: int64 \n","\n","49309    0\n","39185    1\n","872      1\n","7783     0\n","20441    1\n","        ..\n","14945    0\n","42896    1\n","17572    1\n","20051    0\n","22697    1\n","Name: sentiment, Length: 10000, dtype: int64\n"]}]},{"cell_type":"code","source":["def get_max_length():\n","    review_length = []\n","    for review in x_train:\n","        review_length.append(len(review))\n","\n","    return int(np.ceil(np.mean(review_length)))"],"metadata":{"id":"Tb2pC_D8GiVc","executionInfo":{"status":"ok","timestamp":1698476734150,"user_tz":-330,"elapsed":468,"user":{"displayName":"Garima Singh","userId":"07177206605986055763"}}},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":["**Tokenize and Pad/Truncate Reviews**\n","A Neural Network only accepts numeric data, so we need to encode the reviews. I use tensorflow.keras.preprocessing.text.Tokenizer to encode the reviews into integers, where each unique word is automatically indexed (using fit_on_texts method) based on x_train.\n","x_train and x_test is converted into integers using texts_to_sequences method.\n","\n","Each reviews has a different length, so we need to add padding (by adding 0) or truncating the words to the same length (in this case, it is the mean of all reviews length) using tensorflow.keras.preprocessing.sequence.pad_sequences.\n","\n","post, pad or truncate the words in the back of a sentence\n","pre, pad or truncate the words in front of a sentence"],"metadata":{"id":"05rXIfYlGmHj"}},{"cell_type":"code","source":["# ENCODE REVIEW\n","token = Tokenizer(lower=False)    # no need lower, because already lowered the data in load_data()\n","token.fit_on_texts(x_train)\n","x_train = token.texts_to_sequences(x_train)\n","x_test = token.texts_to_sequences(x_test)\n","\n","max_length = get_max_length()\n","\n","x_train = pad_sequences(x_train, maxlen=max_length, padding='post', truncating='post')\n","x_test = pad_sequences(x_test, maxlen=max_length, padding='post', truncating='post')\n","\n","total_words = len(token.word_index) + 1   # add 1 because of 0 padding\n","\n","print('Encoded X Train\\n', x_train, '\\n')\n","print('Encoded X Test\\n', x_test, '\\n')\n","print('Maximum review length: ', max_length)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7lyMW3gpGoVs","executionInfo":{"status":"ok","timestamp":1698476782641,"user_tz":-330,"elapsed":10503,"user":{"displayName":"Garima Singh","userId":"07177206605986055763"}},"outputId":"509ca12a-ba58-45ef-ba7d-5605f322c9a3"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["Encoded X Train\n"," [[    1    41   346 ...  2901   389    66]\n"," [   49     4  2133 ...  4165 10197  4918]\n"," [25102    93   250 ... 17096   284    87]\n"," ...\n"," [    1   162  1236 ...     0     0     0]\n"," [  109 42126   583 ...     0     0     0]\n"," [  359  3736   371 ...     0     0     0]] \n","\n","Encoded X Test\n"," [[ 1445   838   871 ...     0     0     0]\n"," [15608  9013  4464 ...     0     0     0]\n"," [    8   245  1355 ...   175   150   707]\n"," ...\n"," [    2   249   279 ...     0     0     0]\n"," [   23 52988   259 ...     0     0     0]\n"," [    2   800    14 ... 16033  2355  1020]] \n","\n","Maximum review length:  130\n"]}]},{"cell_type":"markdown","source":["**Build Architecture/Model**\n","\n","**Embedding Layer:** in simple terms, it creates word vectors of each word in the word_index and group words that are related or have similar meaning by analyzing other words around them.\n","\n","**LSTM Layer: **to make a decision to keep or throw away data by considering the current input, previous output, and previous memory. There are some important components in LSTM.\n","\n","Forget Gate, decides information is to be kept or thrown away\n","Input Gate, updates cell state by passing previous output and current input into sigmoid activation function\n","Cell State, calculate new cell state, it is multiplied by forget vector (drop value if multiplied by a near 0), add it with the output from input gate to update the cell state value.\n","Ouput Gate, decides the next hidden state and used for predictions"],"metadata":{"id":"OqV9G5UxGx2r"}},{"cell_type":"code","source":["# ARCHITECTURE\n","EMBED_DIM = 32\n","LSTM_OUT = 64\n","\n","model = Sequential()\n","model.add(Embedding(total_words, EMBED_DIM, input_length = max_length))\n","model.add(LSTM(LSTM_OUT))\n","model.add(Dense(1, activation='sigmoid'))\n","model.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n","\n","print(model.summary())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3kg38m7EG3Sx","executionInfo":{"status":"ok","timestamp":1698476837030,"user_tz":-330,"elapsed":1174,"user":{"displayName":"Garima Singh","userId":"07177206605986055763"}},"outputId":"8f9b0d19-8c13-41ed-c5a4-bed5f89c1f9e"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," embedding (Embedding)       (None, 130, 32)           2955840   \n","                                                                 \n"," lstm (LSTM)                 (None, 64)                24832     \n","                                                                 \n"," dense (Dense)               (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 2980737 (11.37 MB)\n","Trainable params: 2980737 (11.37 MB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n","None\n"]}]},{"cell_type":"markdown","source":["\n","Training"],"metadata":{"id":"igOem49THABN"}},{"cell_type":"code","source":["checkpoint = ModelCheckpoint(\n","    'models/LSTM.h5',\n","    monitor='accuracy',\n","    save_best_only=True,\n","    verbose=1\n",")"],"metadata":{"id":"n-yuGwdXG_tq","executionInfo":{"status":"ok","timestamp":1698476869606,"user_tz":-330,"elapsed":459,"user":{"displayName":"Garima Singh","userId":"07177206605986055763"}}},"execution_count":16,"outputs":[]},{"cell_type":"code","source":["model.fit(x_train, y_train, batch_size = 128, epochs = 5, callbacks=[checkpoint])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FjwixacSHE5R","executionInfo":{"status":"ok","timestamp":1698477270984,"user_tz":-330,"elapsed":386916,"user":{"displayName":"Garima Singh","userId":"07177206605986055763"}},"outputId":"33232345-5d94-45db-bb80-b336341b888a"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/5\n","313/313 [==============================] - ETA: 0s - loss: 0.4540 - accuracy: 0.7566\n","Epoch 1: accuracy improved from -inf to 0.75660, saving model to models/LSTM.h5\n","313/313 [==============================] - 75s 229ms/step - loss: 0.4540 - accuracy: 0.7566\n","Epoch 2/5\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["313/313 [==============================] - ETA: 0s - loss: 0.2112 - accuracy: 0.9237\n","Epoch 2: accuracy improved from 0.75660 to 0.92375, saving model to models/LSTM.h5\n","313/313 [==============================] - 68s 218ms/step - loss: 0.2112 - accuracy: 0.9237\n","Epoch 3/5\n","313/313 [==============================] - ETA: 0s - loss: 0.1229 - accuracy: 0.9625\n","Epoch 3: accuracy improved from 0.92375 to 0.96245, saving model to models/LSTM.h5\n","313/313 [==============================] - 69s 221ms/step - loss: 0.1229 - accuracy: 0.9625\n","Epoch 4/5\n","313/313 [==============================] - ETA: 0s - loss: 0.0904 - accuracy: 0.9738\n","Epoch 4: accuracy improved from 0.96245 to 0.97378, saving model to models/LSTM.h5\n","313/313 [==============================] - 70s 224ms/step - loss: 0.0904 - accuracy: 0.9738\n","Epoch 5/5\n","313/313 [==============================] - ETA: 0s - loss: 0.0602 - accuracy: 0.9834\n","Epoch 5: accuracy improved from 0.97378 to 0.98343, saving model to models/LSTM.h5\n","313/313 [==============================] - 68s 218ms/step - loss: 0.0602 - accuracy: 0.9834\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.src.callbacks.History at 0x788aaba49cf0>"]},"metadata":{},"execution_count":17}]},{"cell_type":"markdown","source":["Testing"],"metadata":{"id":"7J5pHTGEIBEI"}},{"cell_type":"code","source":["y_pred = (model.predict(x_test) > 0.5).astype(\"int64\")\n","true = 0\n","for i, y in enumerate(y_test):\n","    if y == y_pred[i]:\n","        true += 1\n","\n","print('Correct Prediction: {}'.format(true))\n","print('Wrong Prediction: {}'.format(len(y_pred) - true))\n","print('Accuracy: {}'.format(true/len(y_pred)*100))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QckB3A_BLYw6","executionInfo":{"status":"ok","timestamp":1698478074982,"user_tz":-330,"elapsed":8351,"user":{"displayName":"Garima Singh","userId":"07177206605986055763"}},"outputId":"70cb4881-fe97-4ede-eb47-a713892ddc90"},"execution_count":23,"outputs":[{"output_type":"stream","name":"stdout","text":["313/313 [==============================] - 8s 25ms/step\n","Correct Prediction: 8755\n","Wrong Prediction: 1245\n","Accuracy: 87.55\n"]}]}]}